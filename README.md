# AI Capstone Project â€“ README

## ğŸ“Œ Project Overview

This project performs **Twitter data scraping, cleaning, sentiment analysis, and visualization** using Selenium, Python, and NLP techniques.

The dataset consists of tweets from AI researchers and public figures, cleaned and processed for analysis. Final outputs include sentiment distributions, tweet frequency trends, and engagement metrics.

---

## ğŸ“ Folder Structure

```
AI-CAPSTONE/
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ all_tweets_combined.csv
â”‚   â”‚   â”œâ”€â”€ geoffreyhinton_tweets.csv
â”‚   â”‚   â”œâ”€â”€ ilyasut_tweets.csv
â”‚   â”‚   â””â”€â”€ karpathy_tweets.csv
â”‚   â”‚
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ cleaned_tweets.csv
â”‚       â””â”€â”€ sentiment_tweets.csv
â”‚
â”œâ”€â”€ results/
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ figures/
â”‚   â”‚   â”œâ”€â”€ engagement_by_sentiment.png
â”‚   â”‚   â”œâ”€â”€ likes_by_sentiment.png
â”‚   â”‚   â”œâ”€â”€ sentiment_distribution.png
â”‚   â”‚   â”œâ”€â”€ tweets_over_time.png
â”‚   â”‚   â”œâ”€â”€ tweets_per_month.png
â”‚   â”‚   â””â”€â”€ most_common_words.png
â”‚
â”œâ”€â”€ docs/
â”‚
â”œâ”€â”€ notebooks/
â”‚
â”œâ”€â”€ outputs/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ nitter_scraper.py
â”‚   â”‚   â””â”€â”€ data_collector.py
â”‚   â”‚
â”‚   â””â”€â”€ selenium_scraper.py
â”‚
â”œâ”€â”€ tests/
â”‚
â””â”€â”€ venv/
```

---

## ğŸš€ Features

* Automated **web scraping** using Selenium
* **Data cleaning**: removing URLs, emojis, punctuation, duplicates
* **Sentiment analysis** using VADER/TextBlob
* **Visual analytics** with Matplotlib + Seaborn
* Multi-user tweet collection for comparison
* Report-ready graphs stored in `reports/figures/`

---

## ğŸ§© Installation

```bash
pip install -r requirements.txt
```

For Selenium:

```bash
pip install selenium webdriver-manager
```

---

## âš™ï¸ How to Run

### 1. Run the Scraper

```bash
python src/selenium_scraper.py
```

### 2. Run Data Cleaning

Processes raw tweets into clean format.

```bash
python src/scraper/data_collector.py
```

### 3. Run Sentiment Analysis

Creates `sentiment_tweets.csv`.

```bash
python notebooks/sentiment_analysis.ipynb
```

### 4. Generate Visualizations

Plots will be saved automatically to:

```
reports/figures/
```

---

## ğŸ“Š Output Files

| File                        | Description                        |
| --------------------------- | ---------------------------------- |
| cleaned_tweets.csv          | Fully cleaned dataset              |
| sentiment_tweets.csv        | Tweets with sentiment labels       |
| sentiment_distribution.png  | Pie/Bar chart of sentiment classes |
| tweets_over_time.png        | Line graph of tweet timeline       |
| tweets_per_month.png        | Monthly tweet activity             |
| engagement_by_sentiment.png | Likes + retweets grouped           |
| most_common_words.png       | Word frequency chart               |

---

## ğŸ“š References

* Python Official Documentation
* Pandas Documentation
* Selenium Documentation
* Publicly available interviews from AI researchers

---

## ğŸ‘¨â€ğŸ’» Author

Generated as part of the **AI Capstone Project**.
